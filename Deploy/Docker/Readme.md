# Docker-based deployment

The docker-based deployment consists of three containers:

* Fluent-Bit
* PostgreSQL
* Ethanol.ContextBuilder

Fluent-Bit and PostgreSQL are publicly accessible:

* tcp/1600 is an input entry point accepting Flowmon's JSON data. These records are then forwarded to the ethanol application for processing.
* tcp/1605 is an entry point for communicating with PostgreSQL. It can be used to populate the enrichment table `enrichment_data` used by ethanol for reading
some extra information for hosts and access the table with a computed context called `host_context`.

The application works by reading the input data from Flowmon and processing them into context-based information.
The resulting data is then stored in PostgreSQL table `host_context`.


![Docker Architecture](EthanolDockerArchitecture.png)

The PostgreSQL database is created with two tables:

Table `enrichment_data` is intended to store additional or supplementary information to enrich the context around computed IP host data: 

```sql
CREATE TABLE IF NOT EXISTS enrichment_data (
    type VARCHAR(32) NOT NULL,
    key VARCHAR(64) NOT NULL,
    value VARCHAR(128),
    reliability REAL,
    validity TSRANGE,
    details JSON
);
```

The meaning of the columns is as follows:

* `type` represents the kind or category of enrichment data.
* `key` serves as a unique identifier or key for the enrichment data. It might link the enrichment data with a host or flow.
* `value` stores the actual enrichment data corresponding to the key. For example, if the key is an IP address, the value could be its geolocation, domain name, device type, or other relevant information.
* `reliability` indicates the trustworthiness or confidence level of the enrichment data. It could be a score between 0 and 1, where 1 means highly reliable, and 0 means not reliable at all.
* `validity` indicates the time range when the enrichment data is considered valid or accurate. After this range, the data might be outdated or less reliable.
* `details` can store more detailed enrichment information in a structured JSON format. This can include nested data, arrays, or other details that don't fit neatly into the table's more rigid structure.

For the various examples of enrichment data see section bellow.

Table `host_context` is intended to store computed context related to IP hosts:

```sql
CREATE TABLE IF NOT EXISTS host_context (    
    key VARCHAR(255) NOT NULL,
    tags JSON,
    initiatedconnections JSON,
    acceptedconnections JSON,
    resolveddomains JSON,
    weburls JSON,
    tlshandshakes JSON,
    validity TSRANGE
);
```

* `key` represents the unique identifier for each IP host, which could be the IP address itself or another related unique value.
* `tags` can store a set of descriptive tags or labels associated with the IP host. These tags come from `enrichment_data` table.
* `initiatedconnections` represents connections that the IP host has initiated. This includes destination IPs, ports, number of flows, packets, duration, and other relevant connection details.
* `acceptedconnections` represents incoming connections that the IP host has accepted. 
* `resolveddomains` contains information about domain names that the IP host has resolved.
* `weburls` lists URLs with which the IP host might have accessed or interacted. It gives insights into the web activity of the host.
* `tlshandshakes` contains information about TLS (Transport Layer Security) handshakes initiated by the IP host. This provides insights into the secure communications of the host and can include details like cipher suites, certificates, or protocols.
* `validity` indicates the time range during which the host's context data is considered valid or accurate. 

## Deployment

Change the working folder to `Publish/Docker` and execute `docker-compose` command to build and run the application.

__Building application:__ Docker compose is used to build the application from the source codes by running the following command:

```bash
docker-compose build
```

__Running the application:__ Run the following command to start the services defined in your Docker Compose file:

```bash
docker-compose up
```

__Stopping the application:__ To stop the running services, run the following command in the same directory where you ran the docker-compose up command:

```bash
docker-compose down
```

__Cleaning environment:__ This command will stop and remove all the containers created by docker-compose up. If you want to remove the containers, networks, and volumes used by your services, you can use the --volumes and --remove-orphans options:

```bash
docker-compose down --volumes --remove-orphans
```

## Usage

The deployed infrastructure is designed to efficiently process flow data and generate host-based context, providing valuable insights into network activity.
The system is accessible through two primary endpoints:

* tcp/1600, which accepts flow data in JSON format generated by the Flowmon exporter tool
* tcp/1605, the port on which the Postgres database listens for incoming requests

After the system is running, you can easily feed it with a continuous stream of netflow data in JSON format using the Flowmon exporter tool.

### Online mode: Export Netflows from flowmonexp5

The configuration for the IPFIX export using the Flowmon exporter is specified in the [probe-ethanol.json](probe-ethanol.json) configuration file.
This file should be uploaded to the `~/flowmonexp` folder on the Flowmon host. To generate IPFIX records in the required JSON format, run the following command on the Flowmon host:

```bash
sudo flowmonexp5 ~/flowmonexp/probe-ethanol.json | while(true); do nc --send-only IP-OF-DOCKER-HOST 1600; sleep 5; done
```

The exporter is set up to listen on the local monitoring interface, and it sends the IPFIX records to the standard output. These records are then consumed by netcat and forwarded to the ethanol context builder for further processing.

### Batch mode: Read flows from JSON file

The JSON file with exported IPFIX records can be sent to the ethanol by using nc tool by the followig command:

```bash
cat SOURCE-JSON-FILE | cat ../webuser1/webuser.flows.json | nc -q 0 IP-OF-DOCKER-HOST 1600
```

Note that `-q 0` option is required to end the connection after sending all data.

### Consume the context

The compute host context is stored in Postgres. It is possible to query the content of the table as follows:

1. Open a terminal or command prompt and connect to the PostgreSQL server. You can use the following command:

```bash
psql -U postgres -W postgres -h IP-OF-DOCKER-HOST:1605 -d ethanol
```

2. Once you're connected to the PostgreSQL server, you can use the following SQL command to query the hostctx table:

```sql
SELECT * FROM host_context;
```

## Enrichment Data

Enrichment data provides tags that can be associated with hosts or flows. The `enrichment_data` table unifies the representation of various data, providing specific information in the `details` column. 

The examples of different data are shown in the following table:

| type | key |value | reliability | validity | details |
| ---- | --- | ---- | ------------| ---------| --------|
| activity_bytes | 192.168.123.254 | 4560.0 | 1 | [2021-11-09 03:30:00,2021-11-09 03:40:00] | {"KeyType":"ip","KeyValue":"192.168.123.254","Source":"activity_bytes","StartTime":"2021-11-09T03:30:00","EndTime":"2021-11-09T03:40:00","Reliability":1,"Module":"ip_activity_new@netmonlab","Data":4560.0} |
| os_by_tcpip | 147.229.13.244 | "Linux" | 1 | [2021-11-09 03:41:07.289802,2021-11-09 03:46:26.679065] | {"KeyType":"ip","KeyValue":"147.229.13.244","Source":"os_by_tcpip","StartTime":"2021-11-09T03:41:07.289802","EndTime":"2021-11-09T03:46:26.679065","Reliability":1,"Module":"os_by_tcpip@collector-enta","Data":"Linux"} |
| NetifyTag | 13.32.216.50 | app.netflix | 1 | [-infinity,infinity] | {"Tag":"app.netflix","ShortName":"Netflix","FullName":"Netflix","Description":"Netflix is an online video streaming service that provides movies, TV shows, documentaries and other video formats.","Url":"https://www.netflix.com","Category":"Streaming Media"} |
| NetifyTag | microsoft | app.microsoft | 1 |  [-infinity,infinity] | {"Tag":"app.microsoft","ShortName":"Microsoft","FullName":"Microsoft","Description":"At Microsoft our mission and values are to help people and businesses throughout the world realize their full potential.","Url":"https://www.microsoft.com","Category":"Business"} |

As you can see, the table stores different types of tags. The tag key can be an IP address, domain name, flow key, or other key-like value.


