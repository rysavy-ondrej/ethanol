# Docker-based deployment

The docker-based deployment conists of three containers:

* Fluent-Bit
* PostreSQL
* Ethanol.ContextBuilder

The only Fluent-Bit is publicly accessible as it performs data stream routing for the application:

* tcp/1600 is an input entry point accepting Flowmon's JSON data. These records are then forwared to ethanol application for processing.
* tcp/1605 is an entry point for communicating with PostreSQL. It can be used to populate enrichment table `hosttags` used by ethanol for reading 
some extra information for hosts and also to access the table with computed context called `hostctx`.

The application works by reading the input data from Flowmon and processing them to context-based information.
The resulting data is then stored in PostreSQL table `hostctx`.

## Deployment

Change working folder to `Publish/Docker` and execute `docker-compose` command to build and run the application.

__Building application:__ Docker compose is used to build the application from the source codes by running the following command:

```bash
docker-compose build
```

__Running the application:__ Run the following command to start the services defined in your Docker Compose file:

```bash
docker-compose up
```

__Stopping the application:__ To stop the running services, run the following command in the same directory where you ran the docker-compose up command:

```bash
docker-compose down
```

__Cleaning environment:__ This command will stop and remove all the containers created by docker-compose up. If you want to remove the containers, networks, and volumes used by your services, you can use the --volumes and --remove-orphans options:

```bash
docker-compose down --volumes --remove-orphans
```

## Usage

The deployed infrastructure is designed to efficiently process flow data and generate host-based context, providing valuable insights into network activity. 
The system is accessible through two primary endpoints:

* tcp/1600, which accepts flow data in JSON format generated by the Flowmon exporter tool
* tcp/1605, the port on which the Postgres database listens for incoming requests

After the system is running, you can easily feed it with a continuous stream of netflow data in JSON format using the Flowmon exporter tool. 

### Export Netflows

The configuration for the IPFIX export using the Flowmon exporter is specified in the [probe-ethanol.json](probe-ethanol.json) configuration file. 
This file should be uploaded to the `~/flowmonexp` folder on the Flowmon host. To generate IPFIX records in the required JSON format, run the following command on the Flowmon host:

```bash
sudo flowmonexp5 ~/flowmonexp/probe-ethanol.json | while(true); do nc --send-only IP-OF-DOCKER-HOST 1600; sleep 5; done
```

The exporter is set up to listen on the local monitoring interface, and it sends the IPFIX records to the standard output. These records are then consumed by netcat and forwarded to the ethanol context builder for further processing.

### Consume the context

The compute host context is stored in Postgres. It is possible to query the content of the table as follows:

1. Open a terminal or command prompt and connect to the PostgreSQL server. You can use the following command:

```bash
psql -U postgres -P postgres -h IP-OF-DOCKER-HOST:1605 -d ethanol
```

2. Once you're connected to the PostgreSQL server, you can use the following SQL command to query the hostctx table:


```sql
SELECT * FROM hostctx;
```

